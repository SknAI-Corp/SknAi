# ğŸ§  SknAI â€“ Dermatology Conversational AI (LLM + RAG)

SknAI is a production-ready, privacy-focused Conversational AI assistant designed for dermatology-related patient queries.  
It uses **RAG (Retrieval-Augmented Generation)** combining:

- ğŸ” **Pinecone** for fast vector similarity search  
- ğŸ§¬ **BioBERT** for domain-specific text embeddings  
- ğŸ¤– **Mistral LLM** for medically sound and patient-friendly responses  
- âš¡ **LangChain** for robust chaining of context + LLM  
- ğŸŒ **FastAPI** for scalable and testable APIs  

---

## ğŸ“ Folder Structure

```
LLM_Conversational_AI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/            â†’ FastAPI endpoints & server
â”‚   â”œâ”€â”€ chat/           â†’ Mistral + LangChain QA setup + CLI loop
â”‚   â”œâ”€â”€ embeddings/     â†’ BioBERT tokenizer, model, and embedding logic
â”‚   â”œâ”€â”€ ingest/         â†’ PDF text extraction, chunking, and Pinecone upload
â”‚   â””â”€â”€ services/       â†’ Session context, conversation memory
â”œâ”€â”€ pipelines/          â†’ CLI tools for embedding PDFs and chatting with AI
â”œâ”€â”€ config/             â†’ Environment variables
â”œâ”€â”€ requirements.txt    â†’ Python dependencies
â”œâ”€â”€ Dockerfile          â†’ Containerization setup
â””â”€â”€ README.md           â†’ Project overview and instructions
```

---

## ğŸš€ Features

- âœ… Medical-grade embeddings via **BioBERT**
- âœ… Real-time context retrieval with **Pinecone**
- âœ… Private **Mistral LLM** access (API-based)
- âœ… Query-aware prompt formatting for each session
- âœ… Session-based **conversation history**
- âœ… **FastAPI** microservice for UI/chatbot integration
- âœ… Modular and extensible architecture
- âœ… CLI + API interface support
- âœ… Ready to **containerize** and deploy

---

## âš™ï¸ Setup

### ğŸ 1. Environment Setup
```bash
git clone <your-repo>
cd LLM_Conversational_AI
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

### ğŸ” 2. Environment Variables

Create `config/.env` with your API keys:

```ini
PINECONE_API_KEY=your-pinecone-api-key
MISTRAL_API_KEY=your-mistral-api-key
PINECONE_ENV=us-east1-gcp
PINECONE_INDEX=sknai
```

> Your app will load this via `os.getenv()` or `dotenv`.

---

## ğŸ“¥ Embedding PDFs

To convert a dermatology book or article into searchable chunks:
```bash
python pipelines/embed_pdf.py path/to/your/book.pdf
```

This will:
- Extract text from PDF
- Clean and chunk it intelligently
- Embed using **BioBERT**
- Upload chunks into **Pinecone**

---

## ğŸ’¬ CLI Assistant

Run the chatbot in your terminal:

```bash
python pipelines/interactive_chat.py
```

Example:
```
> Your question: What is eczema?
AI Response: Eczema is a common...
```

---

## ğŸŒ API Usage

### â–¶ï¸ Run the Server
```bash
uvicorn src.api.main:app --reload
```

### ğŸ“˜ Open Swagger UI
Visit: [http://localhost:8000/docs](http://localhost:8000/docs)

### ğŸ“® Available Endpoints

| Method | Endpoint         | Description                           |
|--------|------------------|---------------------------------------|
| `POST` | `/ask/first`     | Pass a predicted disease to start chat |
| `POST` | `/ask/followup`  | Ask follow-up questions in same session |
| `GET`  | `/`              | Root health check                     |

---

## ğŸ§± System Components

| Module               | Responsibility                                  |
|----------------------|--------------------------------------------------|
| `embedder.py`        | Embeds chunks using BioBERT                     |
| `model_loader.py`    | Loads BioBERT tokenizer & model                 |
| `pdf_utils.py`       | Extracts, cleans, and chunks PDF text           |
| `pinecone_ops.py`    | Handles Pinecone index creation & upload        |
| `chain.py`           | Constructs Mistral RAG pipeline with LangChain  |
| `chat_runner.py`     | CLI interface for interacting with the AI       |
| `context.py`         | Manages session memory for multi-turn dialogue  |
| `routes.py`          | Defines API endpoints using FastAPI             |

---

## ğŸ³ Docker Support

### ğŸ›  Build & Run
```bash
docker build -t sknai-chatbot .
docker run -d -p 8000:8000 --env-file config/.env sknai-chatbot
```

Now your FastAPI server is live at [http://localhost:8000](http://localhost:8000)

---

## ğŸ§ª Testing & Development Tips

- Want to log every API request? Add `logging` to `routes.py`
- Need different embedding models? Swap BioBERT in `embedder.py`
- Want to plug into a frontend UI? Connect your chatbot to `/ask/first` and `/ask/followup` via HTTP

---

## ğŸŒ Future Improvements

- âœ… Unit testing for pipelines and API
- ğŸ“¦ Hugging Face deployment
- ğŸ” Auth middleware (JWT or session tokens)
- ğŸ§  Custom Q&A training on your orgâ€™s documents

---

## ğŸ§  License & Disclaimer

This AI is designed to support educational and informational use only.  
It is **not a replacement for a licensed medical professional**.  
Always consult a real doctor before making health-related decisions.
