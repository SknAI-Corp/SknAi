{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 245.5991, Train Accuracy: 50.57%\n",
      "Epoch 2/10 - Loss: 163.5084, Train Accuracy: 66.59%\n",
      "Epoch 3/10 - Loss: 123.0944, Train Accuracy: 74.96%\n",
      "Epoch 4/10 - Loss: 105.0996, Train Accuracy: 79.09%\n",
      "Epoch 5/10 - Loss: 96.0255, Train Accuracy: 80.00%\n",
      "Epoch 6/10 - Loss: 53.3952, Train Accuracy: 89.96%\n",
      "Epoch 7/10 - Loss: 36.0152, Train Accuracy: 93.14%\n",
      "Epoch 8/10 - Loss: 27.3937, Train Accuracy: 94.28%\n",
      "Epoch 9/10 - Loss: 29.2353, Train Accuracy: 94.09%\n",
      "Epoch 10/10 - Loss: 25.8235, Train Accuracy: 94.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3186: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.76%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ LOAD DATASET\n",
    "# ================================\n",
    "dataset_name = \"Team-SknAI/SknAI_300_v3_11Labels\"\n",
    "datasets = load_dataset(dataset_name)\n",
    "datasets = datasets[\"train\"].train_test_split(test_size=0.2, stratify_by_column=\"label\")\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ DEFINE TRANSFORMATIONS\n",
    "# ================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ CUSTOM DATASET CLASS\n",
    "# ================================\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = self.dataset[idx][\"image\"]\n",
    "\n",
    "            # Convert image to PIL (Fix corrupt images)\n",
    "            img = Image.fromarray(np.array(img).astype(\"uint8\"))\n",
    "\n",
    "            # Ensure image is RGB (Fix grayscale issues)\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            img = self.transform(img)\n",
    "            label = torch.tensor(self.dataset[idx][\"label\"], dtype=torch.long)\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {e}\")\n",
    "            return torch.zeros(3, 224, 224), torch.tensor(0)  # Return black image if error\n",
    "\n",
    "# ================================\n",
    "# 4️⃣ CREATE DATA LOADERS (Fixed)\n",
    "# ================================\n",
    "train_dataset = SkinDataset(datasets[\"train\"], transform)\n",
    "val_dataset = SkinDataset(datasets[\"test\"], transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)  # No multiprocessing\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)  # No multiprocessing\n",
    "\n",
    "# ================================\n",
    "# 5️⃣ DEFINE MODEL\n",
    "# ================================\n",
    "class DenseNet121Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DenseNet121Model, self).__init__()\n",
    "        self.model = timm.create_model(\"densenet121\", pretrained=True, num_classes=num_classes)\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "num_classes = len(datasets[\"train\"].features[\"label\"].names)\n",
    "model = DenseNet121Model(num_classes)\n",
    "\n",
    "# ================================\n",
    "# 6️⃣ TRAINING SETUP\n",
    "# ================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# ================================\n",
    "# 7️⃣ TRAINING LOOP (Fixed)\n",
    "# ================================\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {running_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# ================================\n",
    "# 8️⃣ EVALUATION\n",
    "# ================================\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
