{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ LOAD DATASET\n",
    "# ================================\n",
    "dataset_name = \"Team-SknAI/SknAI_300_v3_11Labels\"\n",
    "datasets = load_dataset(dataset_name)\n",
    "datasets = datasets[\"train\"].train_test_split(test_size=0.2, stratify_by_column=\"label\")\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ DEFINE TRANSFORMATIONS\n",
    "# ================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ CUSTOM DATASET CLASS\n",
    "# ================================\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = self.dataset[idx][\"image\"]\n",
    "\n",
    "            # Convert image to PIL (Fix corrupt images)\n",
    "            img = Image.fromarray(np.array(img).astype(\"uint8\"))\n",
    "\n",
    "            # Ensure image is RGB (Fix grayscale issues)\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            img = self.transform(img)\n",
    "            label = torch.tensor(self.dataset[idx][\"label\"], dtype=torch.long)\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {e}\")\n",
    "            return torch.zeros(3, 224, 224), torch.tensor(0)  # Return black image if error\n",
    "\n",
    "# ================================\n",
    "# 4️⃣ CREATE DATA LOADERS (Fixed)\n",
    "# ================================\n",
    "train_dataset = SkinDataset(datasets[\"train\"], transform)\n",
    "val_dataset = SkinDataset(datasets[\"test\"], transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)  # No multiprocessing\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)  # No multiprocessing\n",
    "\n",
    "# ================================\n",
    "# 5️⃣ DEFINE MODEL\n",
    "# ================================\n",
    "class DenseNet121Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DenseNet121Model, self).__init__()\n",
    "        self.model = timm.create_model(\"densenet121\", pretrained=True, num_classes=num_classes)\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "num_classes = len(datasets[\"train\"].features[\"label\"].names)\n",
    "model = DenseNet121Model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3186: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Loss: 91.9136, Train Accuracy: 65.72%\n",
      "Epoch 2/15 - Loss: 40.6836, Train Accuracy: 84.47%\n",
      "Epoch 3/15 - Loss: 27.0344, Train Accuracy: 89.51%\n",
      "Epoch 4/15 - Loss: 17.0373, Train Accuracy: 93.52%\n",
      "Epoch 5/15 - Loss: 9.9543, Train Accuracy: 96.48%\n",
      "Epoch 6/15 - Loss: 5.6283, Train Accuracy: 98.14%\n",
      "Epoch 7/15 - Loss: 3.5899, Train Accuracy: 98.90%\n",
      "Epoch 8/15 - Loss: 2.5495, Train Accuracy: 99.20%\n",
      "Epoch 9/15 - Loss: 1.8241, Train Accuracy: 99.36%\n",
      "Epoch 10/15 - Loss: 1.6887, Train Accuracy: 99.55%\n",
      "Epoch 11/15 - Loss: 1.3513, Train Accuracy: 99.66%\n",
      "Epoch 12/15 - Loss: 1.3306, Train Accuracy: 99.55%\n",
      "Epoch 13/15 - Loss: 1.4210, Train Accuracy: 99.32%\n",
      "Epoch 14/15 - Loss: 1.7984, Train Accuracy: 99.39%\n",
      "Epoch 15/15 - Loss: 2.9855, Train Accuracy: 98.86%\n",
      "Test Accuracy: 90.15%\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 6️⃣ TRAINING SETUP (Updated)\n",
    "# ================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)  # Cosine annealing for better LR decay\n",
    "\n",
    "# ================================\n",
    "# 7️⃣ TRAINING LOOP (Updated)\n",
    "# ================================\n",
    "EPOCHS = 15 \n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {running_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 8️⃣ EVALUATION\n",
    "# ================================\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
